@Article{shannon,
  Title                    = {Programming a Computer Playing Chess},
  Author                   = {Claude E. Shannon},
  Journal                  = {Philosophical Magazine},
  Year                     = {1959},
  Number                   = {312},
  Volume                   = {Ser.7, 41}
}

@article{alphazero,
  author    = {David Silver and
               Thomas Hubert and
               Julian Schrittwieser and
               Ioannis Antonoglou and
               Matthew Lai and
               Arthur Guez and
               Marc Lanctot and
               Laurent Sifre and
               Dharshan Kumaran and
               Thore Graepel and
               Timothy P. Lillicrap and
               Karen Simonyan and
               Demis Hassabis},
  title     = {Mastering Chess and Shogi by Self-Play with a General Reinforcement
               Learning Algorithm},
  journal   = {CoRR},
  volume    = {abs/1712.01815},
  year      = {2017},
  url       = {http://arxiv.org/abs/1712.01815},
  archivePrefix = {arXiv},
  eprint    = {1712.01815},
  timestamp = {Mon, 13 Aug 2018 16:46:01 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1712-01815.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{stockfish,
	author = {chess enthusiasts et al},
	title = {stockfishchess.org},
	url = {https://github.com/official-stockfish/Stockfish}
}


@article{vonneumann,
	Author = {v.  Neumann, J. },
	Da = {1928/12/01},
	Date-Added = {2020-03-19 18:36:39 -0500},
	Date-Modified = {2020-03-19 18:36:39 -0500},
	Doi = {10.1007/BF01448847},
	Id = {v. Neumann1928},
	Isbn = {1432-1807},
	Journal = {Mathematische Annalen},
	Number = {1},
	Pages = {295--320},
	Title = {Zur Theorie der Gesellschaftsspiele (The Theory of Parlor Games)},
	Ty = {JOUR},
	Url = {https://doi.org/10.1007/BF01448847},
	Volume = {100},
	Year = {1928},
	Bdsk-Url-1 = {https://doi.org/10.1007/BF01448847}}

@techreport{alphabeta,
author = {Hart, Timothy and Edwards, Daniel},
title = {The Alpha-Beta Heuristic},
year = {1961},
institution = {M.I.T.},
publisher = {Massachusetts Institute of Technology},
address = {USA}
}


@article{alphagozero,
	Abstract = {A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated positions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here we introduce an algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo's own move selections and also the winner of AlphaGo's games. This neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning 100--0 against the previously published, champion-defeating AlphaGo.},
	Author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and van den Driessche, George and Graepel, Thore and Hassabis, Demis},
	Da = {2017/10/01},
	Date-Added = {2020-03-19 19:50:55 -0500},
	Date-Modified = {2020-03-19 19:50:55 -0500},
	Doi = {10.1038/nature24270},
	Id = {Silver2017},
	Isbn = {1476-4687},
	Journal = {Nature},
	Number = {7676},
	Pages = {354--359},
	Title = {Mastering the game of Go without human knowledge},
	Ty = {JOUR},
	Url = {https://doi.org/10.1038/nature24270},
	Volume = {550},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1038/nature24270}}


